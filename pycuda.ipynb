{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "authorship_tag": "ABX9TyP0nsJJohNJKYy0SUOPt0OX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OhJin-Soo/ktb_ai/blob/main/pycuda.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pycuda"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RdtBeaOxg4iv",
        "outputId": "fbf2dcbc-e4f8-4bdf-d4dd-bc173b5e80c2"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pycuda\n",
            "  Downloading pycuda-2025.1.2.tar.gz (1.7 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.7 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m68.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pytools>=2011.2 (from pycuda)\n",
            "  Downloading pytools-2025.2.4-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: platformdirs>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from pycuda) (4.4.0)\n",
            "Requirement already satisfied: mako in /usr/local/lib/python3.12/dist-packages (from pycuda) (1.3.10)\n",
            "Collecting siphash24>=1.6 (from pytools>=2011.2->pycuda)\n",
            "  Downloading siphash24-1.8-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.5 in /usr/local/lib/python3.12/dist-packages (from pytools>=2011.2->pycuda) (4.15.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.12/dist-packages (from mako->pycuda) (3.0.2)\n",
            "Downloading pytools-2025.2.4-py3-none-any.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.4/99.4 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading siphash24-1.8-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (103 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.2/103.2 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pycuda\n",
            "  Building wheel for pycuda (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycuda: filename=pycuda-2025.1.2-cp312-cp312-linux_x86_64.whl size=659050 sha256=4b27c40c81331b2bb46b98ad05c18ed88125263e3ae9b582387102eb7e65384b\n",
            "  Stored in directory: /root/.cache/pip/wheels/d5/36/f3/ac5f09d768cad3fa15d5a3449bdfe65c3de58e69d036c73228\n",
            "Successfully built pycuda\n",
            "Installing collected packages: siphash24, pytools, pycuda\n",
            "Successfully installed pycuda-2025.1.2 pytools-2025.2.4 siphash24-1.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v5n81hIogtcE",
        "outputId": "0c8e7470-d5c4-47cc-c8f1-a409dae3ca0b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
          ]
        }
      ],
      "source": [
        "import pycuda.compiler as comp\n",
        "import pycuda.driver as drv\n",
        "import numpy\n",
        "import pycuda.autoinit\n",
        "\n",
        "#pycuda.compiler: CUDA C 코드를 컴파일하기 위한 모듈\n",
        "\n",
        "#pycuda.driver: GPU 디바이스와 상호작용하기 위한 모듈\n",
        "\n",
        "#numpy: CPU에서 데이터 생성 및 처리를 위한 라이브러리\n",
        "\n",
        "#pycuda.autoinit: CUDA 컨텍스트를 자동으로 초기화 (GPU 사용 준비)\n",
        "\n",
        "mod = comp.SourceModule(\n",
        "    \"\"\"\n",
        "__global__ void multiply_them(float *dest, float *a, float *b)\n",
        "{\n",
        "  const int i = threadIdx.x;\n",
        "  dest[i] = a[i] * b[i];\n",
        "}\n",
        "\"\"\"\n",
        ")\n",
        "\n",
        "#SourceModule에 문자열로 CUDA C 코드를 작성하면, PyCUDA가 이를 컴파일합니다.\n",
        "\n",
        "#__global__ void multiply_them(...)\n",
        "\n",
        "#__global__은 GPU에서 실행되는 커널 함수임을 의미합니다.\n",
        "\n",
        "#threadIdx.x\n",
        "#현재 스레드의 인덱스.\n",
        "#CUDA는 수많은 스레드가 병렬로 실행되므로, 각 스레드가 처리할 데이터를 구분하기 위해 사용됩니다.\n",
        "\n",
        "#dest[i] = a[i] * b[i]\n",
        "#각 스레드가 자신의 인덱스 i에 해당하는 요소를 곱해서 결과를 dest에 저장합니다.\n",
        "\n",
        "multiply_them = mod.get_function(\"multiply_them\")\n",
        "\n",
        "a = numpy.random.randn(400).astype(numpy.float32)\n",
        "b = numpy.random.randn(400).astype(numpy.float32)\n",
        "\n",
        "#a와 b는 CPU에서 생성한 난수 벡터 (float32)\n",
        "#dest는 결과를 담을 빈 배열\n",
        "#참고: GPU 연산에서는 데이터 타입이 float32여야 호환이 잘 됩니다.\n",
        "\n",
        "dest = numpy.zeros_like(a)\n",
        "multiply_them(drv.Out(dest), drv.In(a), drv.In(b), block=(400, 1, 1))\n",
        "\n",
        "#drv.In(a): CPU 배열을 GPU로 복사\n",
        "#drv.Out(dest): GPU 연산 결과를 다시 CPU 배열로 복사\n",
        "#block=(400, 1, 1):\n",
        "#스레드 블록 크기를 설정.\n",
        "#여기서는 400개의 스레드를 1차원으로 배치\n",
        "#즉, 각 스레드가 1개의 요소를 처리\n",
        "#주의: 이 예제에서는 400개의 스레드를 한 블록에 넣었지만, 실제 큰 배열에서는 여러 블록으로 나눠야 합니다.\n",
        "\n",
        "print(dest - a * b)\n",
        "\n",
        "#GPU 연산 결과 dest와 CPU에서 직접 계산한 a*b를 비교\n",
        "#거의 0에 가까운 값이 나와야 정상 (부동소수점 오차 수준)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cupy\n",
        "\n",
        "#CuPy는 NumPy와 거의 동일한 API를 제공하지만, 내부 연산을 CUDA GPU에서 실행합니다.\n",
        "#즉, numpy 대신 cupy를 쓰면 자동으로 GPU 가속이 되는 느낌.\n",
        "\n",
        "a = cupy.random.randn(400)\n",
        "b = cupy.random.randn(400)\n",
        "\n",
        "#cupy.random.randn → GPU 메모리 위에서 난수 배열 생성 (numpy.random.randn과 같은 역할, but GPU 버전).\n",
        "#결과는 GPU 메모리에 저장된 배열(cupy.ndarray).\n",
        "\n",
        "dest = cupy.zeros_like(a)\n",
        "\n",
        "#a와 같은 shape, dtype을 가지는 GPU 배열 생성 (모두 0으로 초기화).\n",
        "\n",
        "print(dest - a * b)\n",
        "\n",
        "#a * b: GPU에서 벡터 곱 (원소별 곱).\n",
        "#dest - a * b: 결과를 빼기 → 사실 dest는 0이므로, 결과는 단순히 -a*b.\n",
        "#즉, \"a와 b의 원소별 곱을 구한 뒤, 그것에 마이너스를 붙여서 출력\" 한 것."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OexZBIuijGRB",
        "outputId": "15b210d5-0f76-4301-b7f2-bd3c19bcf756"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-9.11687716e-02 -2.82092405e-01  1.56302978e-01  8.99207677e-01\n",
            "  3.14157732e-01  1.31768510e+00 -4.72836709e-02 -1.14595615e-01\n",
            " -2.55442244e-01  3.09299746e+00 -3.29755154e-01 -6.08423389e-01\n",
            " -3.31611400e-01  5.44487054e-01 -5.16687183e-01 -7.72562122e-01\n",
            "  8.99675581e-01  1.16866174e-01  1.59935167e-01 -3.63125248e-01\n",
            " -1.43849025e-01  6.08904930e-01 -7.54232787e-02 -4.13442076e-01\n",
            " -2.73772939e-01  5.87625624e-01 -3.09636121e+00 -8.64615811e-02\n",
            "  1.06907107e+00 -1.05752071e+00 -2.54348813e-01  2.38669069e-01\n",
            "  4.13698282e-02  3.33077784e-01 -4.39438685e-02 -3.57990095e+00\n",
            "  6.51075337e-01  1.87956050e-01  6.15157298e-02  4.51325003e-01\n",
            "  4.15904762e-02 -3.11410153e-01 -5.80417879e-02 -2.11261702e-02\n",
            " -1.44597404e+00 -9.70216198e-01  2.15212350e-01  3.22572894e-02\n",
            "  1.94744761e+00 -1.43345498e+00  1.51876221e-01  4.32512857e-01\n",
            "  1.70544603e-01 -1.46244405e+00 -2.10011680e-01 -5.78880929e-01\n",
            " -1.87465729e-01  1.38300144e+00 -3.31405061e-02 -1.08517473e-01\n",
            "  3.47502943e-01  5.23031613e-01 -4.84138681e-01  1.18063983e-01\n",
            "  1.06972748e+00  1.93162071e+00 -8.10323303e-03  1.13438914e+00\n",
            "  8.46953830e-01 -1.39863618e-01 -2.43863796e-01  2.54727992e-01\n",
            "  3.95615641e-01 -1.00305383e+00  1.40538925e-01  3.48938634e+00\n",
            "  1.28532573e-01 -1.89395937e+00 -3.15674435e-01 -3.12030277e-02\n",
            " -7.32810250e-01 -6.46089104e+00 -8.06497689e-02 -1.04488386e+00\n",
            " -9.59673313e-01  2.00724450e-01  5.89819186e-01  2.13190179e-01\n",
            " -2.67860275e-01  9.35904115e-01  4.89753440e-01  6.40082903e-01\n",
            "  7.43011991e-01  1.21096432e+00  3.85328102e-01 -8.33989515e-01\n",
            "  1.40787241e-01 -3.84069230e-01 -3.07997690e-01  5.20512227e-01\n",
            "  8.35866136e-01 -4.25848641e-03 -2.00624014e-02 -1.79428623e-01\n",
            "  9.09591140e-02 -1.14105875e-01 -8.26160987e-01  1.44846486e-02\n",
            " -9.28684813e-02 -2.66810640e-02 -5.60883442e-01  7.53640854e-02\n",
            "  2.42180895e+00 -2.78977767e-01 -6.74431091e-01 -1.14174539e+00\n",
            "  2.27992929e-02 -3.21750990e-02  5.75627756e-01 -1.17604356e-01\n",
            " -1.39270499e+00  4.57456559e-01  3.26450455e-03  4.34681367e-01\n",
            "  3.44148295e-01 -1.13629709e-01 -4.08127856e-02 -6.82975877e-02\n",
            "  1.09928153e+00 -2.87547516e-02  2.99217055e-01  1.69211782e+00\n",
            " -1.49476453e+00  8.28985265e-01 -3.03335959e-01 -3.49526638e-01\n",
            " -1.08001141e+00 -2.53673678e+00 -7.17333124e-02  4.86804614e-01\n",
            "  5.12734941e-01 -3.65812719e-02  9.73099516e-01 -8.25232001e-02\n",
            " -4.65861195e-01 -1.57341483e+00  5.66481875e-01  3.61892005e-01\n",
            " -4.88039580e-02 -2.94301789e-02 -1.12993382e+00  8.09506842e-01\n",
            " -5.10591972e-01 -9.81108609e-01 -2.38603973e+00 -5.35985399e-01\n",
            " -1.66059100e+00 -1.90255696e-04  3.33753001e-02  6.84357075e-02\n",
            " -1.56790574e+00 -8.16376697e-03  3.57758307e-02  2.70295866e+00\n",
            "  3.26104298e-01  1.78428655e+00 -4.31246067e-02 -1.24435373e+00\n",
            "  7.93957806e-01  6.72894277e-01  2.92038046e-01  1.39793255e-01\n",
            "  2.15609247e-01 -3.02793306e-01 -1.85613837e-01  4.95703059e+00\n",
            " -8.13175570e-01 -1.58736927e-01 -1.54648305e-01 -4.10948525e-01\n",
            "  4.78171821e-01 -5.23944055e-02 -1.42472950e-01  1.10234614e-01\n",
            "  4.47401418e-01  3.60704606e-02  1.51875022e-01 -4.78519819e-01\n",
            "  1.19982690e-01  7.00480257e-01 -8.43142208e-01  3.48753049e-01\n",
            " -9.59080164e-01  3.15768137e-01 -2.11196419e-03  8.04585021e-02\n",
            "  1.38590420e-02 -4.74077024e-01 -1.77263057e-01 -1.90202866e+00\n",
            "  1.66733233e-01 -1.39011894e+00 -4.37235405e-01 -2.12816681e-01\n",
            " -2.27551649e-01 -1.95609556e-02 -1.89237734e-01 -1.12011561e-01\n",
            "  2.31052471e-01 -7.71626422e-01  8.94469476e-01  1.26435683e+00\n",
            "  1.10344168e+00 -1.09284165e-01 -7.65545075e-01 -7.59642380e-01\n",
            " -2.36454294e-01 -1.21771593e-01  5.32292618e-01 -1.92975596e+00\n",
            " -2.22358381e+00  7.19508683e-03  5.70651831e-02 -1.22066038e+00\n",
            " -1.12148819e-01  1.47625227e-01 -3.77765403e-01 -6.07276271e-02\n",
            " -1.14363037e-01  2.06566738e+00  6.17699917e-01  4.86580870e-02\n",
            " -1.66636465e+00 -1.43793430e-02 -2.06036982e-01 -7.12569055e-01\n",
            " -2.08346905e-01  1.52119768e+00  6.09752517e-01 -1.21862555e+00\n",
            " -4.46915682e-01 -3.88416697e-01 -7.01921857e-01  1.01375607e-01\n",
            "  9.17019590e-01 -1.06256480e+00 -1.95359210e-02  3.21420990e-01\n",
            "  8.34139567e-01  2.21833039e+00 -5.89775391e-01  1.88041739e-01\n",
            "  3.01398768e+00  6.08000250e-01  1.18215441e+00  2.40501932e-01\n",
            " -2.69552789e-01 -4.40883628e-01 -2.81537840e-01 -6.52059934e-03\n",
            "  2.69343518e+00  1.61637407e+00 -2.06727228e-01 -3.95311606e-01\n",
            "  2.80603654e+00 -7.98114979e-02  6.42818501e-01 -8.88019778e-01\n",
            "  1.81492347e-01 -4.38938443e-01 -1.33494486e+00 -2.84174463e-01\n",
            "  6.54138279e-02 -9.26836797e-02  1.37780671e+00  8.19464043e-01\n",
            " -2.33899217e-03  8.41264985e-01  5.44796239e-03  2.64395414e-01\n",
            " -8.80029954e-04 -3.39145416e-01  6.76032068e+00  4.03391706e-01\n",
            " -2.09881507e-01 -9.22746835e-02  3.70506746e-01  3.09693420e-01\n",
            "  2.10314891e-01  4.82474504e-01 -3.12388407e-01  8.42599032e-01\n",
            " -3.15816908e+00  2.79444956e-01 -1.36724956e-01  3.61897579e-01\n",
            "  3.39661567e-01  7.03721030e-01  1.40735142e+00  2.42082133e-01\n",
            "  2.91151720e+00 -2.43961243e-01  1.47053310e-02  9.54225280e-01\n",
            " -9.81759057e-02 -3.63526795e-02 -1.52026416e-01 -1.69979403e-02\n",
            " -1.76568788e-01  7.26276048e-01 -5.03084434e-01  1.35601883e+00\n",
            " -1.58607488e-01 -1.33515101e-01  5.43983767e-01 -3.92056856e-03\n",
            "  4.53556375e-01  3.88415410e-02  7.06501746e-01 -1.01703956e+00\n",
            " -1.87136151e-01 -3.79554341e-02 -2.36944317e-01 -4.14239175e-02\n",
            "  2.77445680e+00  3.40422174e-01  1.22068785e-02  4.61177708e-01\n",
            " -1.02152147e+00  4.06897147e-01  9.30827016e-01 -3.47696534e-02\n",
            "  6.36420604e-01 -2.13617938e-01  4.43375152e-01 -3.69808241e-01\n",
            " -2.77875714e+00 -2.59850553e-02 -4.63958609e-01  1.07015598e+00\n",
            "  4.13916580e-01 -7.80301438e-02 -5.08454978e-01  6.45628593e-01\n",
            " -7.39552237e-02 -1.19885295e+00  4.06408516e-01  1.31508380e+00\n",
            "  1.32575561e+00 -4.55907309e-01  6.50814514e-01  2.56124982e-01\n",
            " -1.32526066e+00 -1.08180977e-02 -5.47656963e-01 -2.84262099e-01\n",
            " -5.10475543e-01  1.22017236e+00 -1.85204345e-01 -8.77848463e-01\n",
            " -5.98302423e-01  6.69559248e-03 -1.82603308e-02  5.47237792e-02\n",
            "  1.15150470e-02 -1.57567782e+00 -7.90263917e-02  1.01744711e+00\n",
            "  5.42130995e-02 -1.46805068e-01 -6.43774217e-03  1.49548141e-01\n",
            " -2.61823973e-01  1.05436597e-02  1.34790589e+00  4.13478195e-01\n",
            "  3.58471171e+00 -3.41789265e-01  1.17961301e+00  1.02790223e-01\n",
            " -8.01187528e-02 -8.83722964e-03 -5.85193336e-02  1.75075982e-01\n",
            "  4.30203511e-01  3.32557468e-01  4.16895095e-01 -4.31810379e-01\n",
            " -1.54729147e+00 -5.74403799e-02 -7.76627567e-02 -5.65508753e-02\n",
            "  5.46076313e-01 -1.91870739e-01  7.24268737e-01 -9.97480789e-01\n",
            " -6.94247787e-01  4.77794541e-03  3.54298415e+00  1.58056963e-01]\n"
          ]
        }
      ]
    }
  ]
}